{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/miniconda3/envs/deep_bayesian_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('.')  \n",
    "\n",
    "import pyro\n",
    "import torch\n",
    "\n",
    "from data.mushroom_data import load_mushroom_data\n",
    "\n",
    "from model.pyrobayesian1dcnn import PyroBayesian1DCNN\n",
    "from train.train import train_model\n",
    "from train.evaluate import evaluate_model\n",
    "from train.hyperparam_opt import run_hyperparam_optimization\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "pyro.set_rng_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation de : cpu\n",
      "tab2seq.linear.weight: cpu\n",
      "tab2seq.linear.bias: cpu\n",
      "bn1.weight: cpu\n",
      "bn1.bias: cpu\n",
      "bn2.weight: cpu\n",
      "bn2.bias: cpu\n",
      "[Epoch 1] Loss: 0.7491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-21 15:05:41,750] A new study created in memory with name: no-name-2dcdd88f-2a0d-4661-90e8-40f329921e7b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 (simple config) = 52.84%\n",
      "Utilisation de : cpu\n",
      "tab2seq.linear.weight: cpu\n",
      "tab2seq.linear.bias: cpu\n",
      "bn1.weight: cpu\n",
      "bn1.bias: cpu\n",
      "bn2.weight: cpu\n",
      "bn2.bias: cpu\n",
      "[Epoch 1] Loss: 0.7720\n",
      "[Epoch 2] Loss: 0.7707\n",
      "[Epoch 3] Loss: 0.7678\n",
      "[Epoch 4] Loss: 0.7747\n",
      "[Epoch 5] Loss: 0.7650\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, input_dim = load_mushroom_data(\n",
    "    batch_size=64,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model = PyroBayesian1DCNN(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=1,\n",
    "    proj_channels=16,\n",
    "    proj_seq_len=4,\n",
    "    conv_out_channels=32,\n",
    "    kernel_size=3,\n",
    "    prior_std=0.1\n",
    ")\n",
    "\n",
    "svi = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    num_epochs=1,\n",
    "    lr=0.001,\n",
    "    num_particles=1\n",
    ")\n",
    "\n",
    "f1_simple = evaluate_model(model, test_loader, num_samples=10)\n",
    "print(f\"f1 (simple config) = {f1_simple*100:.2f}%\")\n",
    "\n",
    "study = run_hyperparam_optimization(n_trials=10) \n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparams found by Optuna:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 1.0407\n",
      "[Epoch 2] Loss: 1.0496\n",
      "[Epoch 3] Loss: 1.0548\n",
      "[Epoch 4] Loss: 1.0298\n",
      "[Epoch 5] Loss: 1.0387\n",
      "[Epoch 6] Loss: 1.0277\n",
      "[Epoch 7] Loss: 1.0505\n",
      "[Epoch 8] Loss: 1.0514\n",
      "[Epoch 9] Loss: 1.0542\n",
      "[Epoch 10] Loss: 1.0396\n",
      "Accuracy (optimized) = 52.66%\n"
     ]
    }
   ],
   "source": [
    "model_optimized = PyroBayesian1DCNN(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=1,\n",
    "    proj_channels=best_params[\"proj_channels\"],\n",
    "    proj_seq_len=best_params[\"proj_seq_len\"],\n",
    "    conv_out_channels=best_params[\"conv_out_channels\"],\n",
    "    kernel_size=best_params[\"kernel_size\"],\n",
    "    prior_std=best_params[\"prior_std\"]\n",
    ")\n",
    "\n",
    "pyro.set_rng_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "svi_opt = train_model(\n",
    "    model=model_optimized,\n",
    "    train_loader=train_loader,\n",
    "    num_epochs=best_params[\"num_epochs\"],\n",
    "    lr=best_params[\"lr\"],\n",
    "    num_particles=1\n",
    ")\n",
    "\n",
    "f1_opt = evaluate_model(model_optimized, test_loader, num_samples=10)\n",
    "print(f\"F1 (optimized) = {f1_opt*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_bayesian_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
